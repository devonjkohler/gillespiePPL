{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9c6528a-0137-4759-a8e1-5538d9a761ca",
   "metadata": {},
   "source": [
    "# Gillespie rate inference using SBI (Simulation Based Inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e23b51d-1d8e-416e-ab5e-7d60ed43f17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sbi.utils as utils\n",
    "from sbi.inference.base import infer\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tellurium as te"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fd8fca-a607-4351-b662-b6d05760e77f",
   "metadata": {},
   "source": [
    "## Lotka Volterra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23f7a22-2e53-46c3-a89c-256adbad1a3c",
   "metadata": {},
   "source": [
    "### Define Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff8b6729-5936-4292-9856-ce48a498e14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define simulator\n",
    "def lv_simulator(propose_rates):\n",
    "\n",
    "    t = 0.\n",
    "    stop_time = 5000. # Length of sim\n",
    "    s = torch.tensor([20., 40.]) # Starting points\n",
    "    path = np.insert(s, 0, t, axis=0).reshape(1, 3)\n",
    "\n",
    "    ## Hazard functions\n",
    "    rate_functions = [lambda s: propose_rates[0] * s[0],\n",
    "                      lambda s: propose_rates[1] * s[1] * s[0],\n",
    "                      lambda s: propose_rates[2] * s[1]]\n",
    "    n_func = len(rate_functions)\n",
    "\n",
    "    transition_matrix = torch.tensor([[1, 0], [-1, 1], [0, -1]])\n",
    "\n",
    "    # Run sim until time limit is reached\n",
    "    while True:\n",
    "\n",
    "        sampling_weights = [f(s) for f in rate_functions]\n",
    "        total_weight = sum(sampling_weights)\n",
    "\n",
    "        # Sample a rate\n",
    "        probs = np.array([weight / total_weight for weight in sampling_weights])\n",
    "        sample = np.random.choice(n_func, p=probs)\n",
    "        t += np.random.exponential(1.0 / total_weight)\n",
    "\n",
    "        if t >= stop_time:\n",
    "            break\n",
    "\n",
    "        # Update species\n",
    "        s = s + transition_matrix[sample]\n",
    "\n",
    "        # Add some noise to outputs\n",
    "        s = torch.normal(s, .25)\n",
    "        s[0] = max(1, s[0])\n",
    "        s[1] = max(1, s[1])\n",
    "\n",
    "        path = torch.cat((path, np.insert(s, 0, t, axis=0).reshape(1, 3)), axis=0)\n",
    "\n",
    "    path = torch.cat((path, np.insert(s, 0, stop_time, axis = 0).reshape(1, 3)), axis=0)\n",
    "    path = torch.flatten(path)\n",
    "\n",
    "    # Mask values onto long tensor so that all samples are of equal length\n",
    "    mask_len = 10000 - len(path)\n",
    "    mask = torch.tensor([-1 for _ in range(mask_len)])\n",
    "    path = torch.cat((path, mask), 0)\n",
    "\n",
    "    return path[3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae559d4d-3885-4554-bd92-79dcbf2497fa",
   "metadata": {},
   "source": [
    "### Define Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21598a5f-af56-462d-891e-4bb5a6922e88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Choose a prior\n",
    "prior = utils.BoxUniform(\n",
    "    low=torch.tensor([0.0005, 0.0001, 0.0005]),\n",
    "    high=torch.tensor([0.005, 0.0005, 0.005])\n",
    ")\n",
    "\n",
    "# Only uniform prior implemented into sbi package currently\n",
    "# Easy to add more manually, for example log normal\n",
    "# prior = utils.LogNormalPrior(\n",
    "#     torch.tensor([np.log(.0015),\n",
    "#                   np.log(.0002),\n",
    "#                   np.log(.003)]), .25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9f746c-83ff-47f5-b400-0c47184b17ab",
   "metadata": {},
   "source": [
    "### Run inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272ac7de-5956-4e78-99ad-453f309e2bd3",
   "metadata": {},
   "source": [
    "Currently only SNPE and SNLE run without error. SNRE has issues with masked values at end of simulation (-1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9741aaa3-1cdb-4380-91a1-f9ab2bfac040",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b789ba74b0494939b02a63ed774a95f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 500 simulations in 500 batches.:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Neural network successfully converged after 36 epochs."
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "num_sim = 500\n",
    "method = 'SNPE' #SNPE or SNLE or SNRE\n",
    "posterior = infer(\n",
    "    lv_simulator,\n",
    "    prior,\n",
    "    method=method,\n",
    "    num_workers=-1,\n",
    "    num_simulations=num_sim\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a179841-926d-47cd-916a-75c97c2daed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample some observations with known ground truth\n",
    "obs = torch.tensor([lv_simulator([0.001, 0.0002, 0.003]).numpy() for _ in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3db902f-1241-4daa-bd81-4e1bd7c3552b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4a4f3a43f6c4657b4dc5a6ccc99aed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 500 posterior samples:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sample the posterior and plot results\n",
    "samples = posterior.sample((500,), x=obs[0]) # SNPE only works with one obs, SNLE will work with more\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(10,6))\n",
    "ax[0].hist(samples[:, 0].numpy(), bins=15)\n",
    "ax[1].hist(samples[:, 1].numpy(), bins=15)\n",
    "ax[2].hist(samples[:, 2].numpy(), bins=15)\n",
    "ax[0].axvline(x = .001, color = \"red\")\n",
    "ax[1].axvline(x = .0002, color = \"red\")\n",
    "ax[2].axvline(x = .003, color = \"red\")\n",
    "\n",
    "ax[0].set_title(\"r1 samples\")\n",
    "ax[1].set_title(\"r2 samples\")\n",
    "ax[2].set_title(\"r3 samples\")\n",
    "\n",
    "plt.suptitle(\"Lotka Volterra SNPE Rate Inference\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b7141e-22f7-474d-9f88-95267da73e97",
   "metadata": {},
   "source": [
    "SNLE has a fairly tight posterior but is usually biased compared to the ground truth rates. This may be due to a low dimensional input (3) but high dimensional output (10000)? SNPE usually contains the true rate but is A. biased towards what observation is passed and B. has a much wider posterior than SNLE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5c58fe-703a-485e-ab42-0c47afd86671",
   "metadata": {},
   "source": [
    "## Lac Operon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d94260-81a5-4e3c-afc4-0e98a1db8515",
   "metadata": {},
   "source": [
    "Used https://github.com/vivarium-collective/vivarium-notebooks/blob/main/notebooks/Lac_Operon_CRN.ipynb to build lac operon model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b756e24-b286-498c-be2d-4e27dd6dc14e",
   "metadata": {},
   "source": [
    "### Print Model Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "26d6c286-02fa-4e48-9c2e-b7e18a391c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use Tellurium to print model details\n",
    "ant_lo = te.sbmlToAntimony(r\"../data/LacOperon/LacOperon_stochastic.xml\")\n",
    "model_lo = te.loadSBMLModel(r\"../data/LacOperon/LacOperon_stochastic.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a42c5214-0ece-4613-a9ea-b8b950dca2c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "// Created by libAntimony v2.12.0\n",
      "model *biocrnpyler_24259()\n",
      "\n",
      "  // Compartments and Species:\n",
      "  compartment default;\n",
      "  species rna_M in default, monomer_betaGal in default, protein_betaGal in default;\n",
      "  species Lactose_external in default, Lactose_internal in default, Glucose_external in default;\n",
      "  species Glucose_internal in default, protein_Lactose_Permease in default;\n",
      "  species dna_Lac_Operon in default, Biomass in default, Lactose_consumed in default;\n",
      "\n",
      "  // Reactions:\n",
      "  r0: dna_Lac_Operon => dna_Lac_Operon + rna_M; dna_Lac_Operon*r0_Vtx*(r0_k_leak + (Lactose_internal^r0_n_L/(r0_K_L^r0_n_L + Lactose_internal^r0_n_L))*(1/(1 + (Glucose_external/r0_K_G)^r0_n_G)));\n",
      "  r1: rna_M => rna_M + monomer_betaGal; k_tl_beta_Gal__*rna_M;\n",
      "  r2: rna_M => rna_M + protein_Lactose_Permease; k_tl_lacP__*rna_M;\n",
      "  r3: 4 monomer_betaGal => protein_betaGal; BGal_tetramerization__*monomer_betaGal*(monomer_betaGal - 1)*(monomer_betaGal - 2)*(monomer_betaGal - 3);\n",
      "  r4: Lactose_internal => Lactose_consumed; BGal_vmax__*protein_betaGal*Lactose_internal^r4_n/(Bgal_Kd__^r4_n + Lactose_internal^r4_n);\n",
      "  r5: Glucose_external => Glucose_internal; GluPermease_vmax__*Biomass*Glucose_external^r5_n/(GluPermease_Kd__^r5_n + Glucose_external^r5_n);\n",
      "  r6: Lactose_external => Lactose_internal; (protein_Lactose_Permease*r6_LacPermease_vmax*Lactose_external/(Lactose_external + r6_LacPermease_Kd))*(1 - r6_phi_G*Glucose_external/(r6_GluPermease_Kd + Glucose_external));\n",
      "  r7: Lactose_internal => Lactose_external; LacPermease_reverse_vmax__*protein_Lactose_Permease*Lactose_internal^r7_n/(LacPermease_Kd__^r7_n + Lactose_internal^r7_n);\n",
      "  r8: rna_M => ; kdeg_mRNA__*rna_M;\n",
      "  r9: protein_betaGal => ; kdeg_prot__*protein_betaGal;\n",
      "  r10: protein_Lactose_Permease => ; kdeg_prot__*protein_Lactose_Permease;\n",
      "\n",
      "  // Species initializations:\n",
      "  rna_M = 0;\n",
      "  rna_M has mole_per_volume;\n",
      "  monomer_betaGal = 0;\n",
      "  monomer_betaGal has mole_per_volume;\n",
      "  protein_betaGal = 0;\n",
      "  protein_betaGal has mole_per_volume;\n",
      "  Lactose_external = 120440000;\n",
      "  Lactose_external has mole_per_volume;\n",
      "  Lactose_internal = 0;\n",
      "  Lactose_internal has mole_per_volume;\n",
      "  Glucose_external = 60220000;\n",
      "  Glucose_external has mole_per_volume;\n",
      "  Glucose_internal = 0;\n",
      "  Glucose_internal has mole_per_volume;\n",
      "  protein_Lactose_Permease = 0;\n",
      "  protein_Lactose_Permease has mole_per_volume;\n",
      "  dna_Lac_Operon = 2;\n",
      "  dna_Lac_Operon has mole_per_volume;\n",
      "  Biomass = 1000;\n",
      "  Biomass has mole_per_volume;\n",
      "  Lactose_consumed = 0;\n",
      "  Lactose_consumed has mole_per_volume;\n",
      "\n",
      "  // Compartment initializations:\n",
      "  default = 1e-06;\n",
      "\n",
      "  // Variable initializations:\n",
      "  k_tl_beta_Gal__ = 0.156666666666667;\n",
      "  k_tl_lacP__ = 0.313333333333333;\n",
      "  BGal_tetramerization__ = 1000;\n",
      "  BGal_vmax__ = 300;\n",
      "  Bgal_Kd__ = 84310;\n",
      "  GluPermease_vmax__ = 301;\n",
      "  GluPermease_Kd__ = 9033;\n",
      "  LacPermease_reverse_vmax__ = 1.18966666666667;\n",
      "  LacPermease_Kd__ = 8800000;\n",
      "  kdeg_mRNA__ = 0.00783333333333333;\n",
      "  kdeg_prot__ = 0.000166666666666667;\n",
      "  r0_Vtx = 0.003;\n",
      "  r0_n_L = 4;\n",
      "  r0_K_L = 2900000;\n",
      "  r0_K_G = 1506;\n",
      "  r0_n_G = 2;\n",
      "  r0_k_leak = 0.05;\n",
      "  r4_n = 1;\n",
      "  r5_n = 1;\n",
      "  r6_GluPermease_Kd = 9033;\n",
      "  r6_LacPermease_vmax = 35.8;\n",
      "  r6_LacPermease_Kd = 156576;\n",
      "  r6_phi_G = 0.35;\n",
      "  r7_n = 1;\n",
      "\n",
      "  // Other declarations:\n",
      "  const default, k_tl_beta_Gal__, k_tl_lacP__, BGal_tetramerization__, BGal_vmax__;\n",
      "  const Bgal_Kd__, GluPermease_vmax__, GluPermease_Kd__, LacPermease_reverse_vmax__;\n",
      "  const LacPermease_Kd__, kdeg_mRNA__, kdeg_prot__;\n",
      "\n",
      "  // Unit definitions:\n",
      "  unit square_metre = metre^2;\n",
      "  unit length = metre;\n",
      "  unit area = square_metre;\n",
      "  unit volume = litre;\n",
      "  unit substance = mole;\n",
      "  unit extent = mole;\n",
      "  unit time_unit = second;\n",
      "  unit mole_per_volume = mole / litre;\n",
      "\n",
      "  // Display Names:\n",
      "  rna_M is \"M\";\n",
      "  monomer_betaGal is \"betaGal\";\n",
      "  protein_betaGal is \"betaGal\";\n",
      "  Lactose_external is \"Lactose\";\n",
      "  Lactose_internal is \"Lactose\";\n",
      "  Glucose_external is \"Glucose\";\n",
      "  Glucose_internal is \"Glucose\";\n",
      "  protein_Lactose_Permease is \"Lactose_Permease\";\n",
      "  dna_Lac_Operon is \"Lac_Operon\";\n",
      "  Lactose_consumed is \"Lactose\";\n",
      "end\n",
      "\n",
      "biocrnpyler_24259 is \"biocrnpyler_24259\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ant_lo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cf65b8e7-7752-4829-a3cf-ed62c412bb83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                            r0, r1, r2, r3, r4, r5, r6, r7, r8, r9, r10\n",
       "rna_M                    [[  1,  0,  0,  0,  0,  0,  0,  0, -1,  0,   0],\n",
       "monomer_betaGal           [  0,  1,  0, -4,  0,  0,  0,  0,  0,  0,   0],\n",
       "protein_betaGal           [  0,  0,  0,  1,  0,  0,  0,  0,  0, -1,   0],\n",
       "Lactose_external          [  0,  0,  0,  0,  0,  0, -1,  1,  0,  0,   0],\n",
       "Lactose_internal          [  0,  0,  0,  0, -1,  0,  1, -1,  0,  0,   0],\n",
       "Glucose_external          [  0,  0,  0,  0,  0, -1,  0,  0,  0,  0,   0],\n",
       "Glucose_internal          [  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,   0],\n",
       "protein_Lactose_Permease  [  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  -1],\n",
       "dna_Lac_Operon            [  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,   0],\n",
       "Biomass                   [  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,   0],\n",
       "Lactose_consumed          [  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,   0]]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Transistion matrix\n",
    "model_lo.getFullStoichiometryMatrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8ecb4a-49c8-4695-bc68-bed449f38ee4",
   "metadata": {},
   "source": [
    "### Define Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "95ae2efc-8e4f-4f55-af08-de08f1902904",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_names = ['k_tl_beta_Gal__',\n",
    "    'k_tl_lacP__',\n",
    "    'BGal_tetramerization__',\n",
    "    'BGal_vmax__',\n",
    "    'Bgal_Kd__',\n",
    "    'GluPermease_vmax__',\n",
    "    'GluPermease_Kd__',\n",
    "    'LacPermease_reverse_vmax__',\n",
    "    'LacPermease_Kd__',\n",
    "    'kdeg_mRNA__',\n",
    "    'kdeg_prot__',\n",
    "    'r0_Vtx',\n",
    "    'r0_n_L',\n",
    "    'r0_K_L',\n",
    "    'r0_K_G',\n",
    "    'r0_n_G',\n",
    "    'r0_k_leak',\n",
    "    'r4_n',\n",
    "    'r5_n',\n",
    "    'r6_GluPermease_Kd',\n",
    "    'r6_LacPermease_vmax',\n",
    "    'r6_LacPermease_Kd',\n",
    "    'r6_phi_G',\n",
    "    'r7_n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1cbc1a33-0b43-40b0-93c8-d894309a90cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define simulator\n",
    "def lac_operon_simulator(propose_rates):\n",
    "\n",
    "    t = 0.\n",
    "    #stop_time = 10. # Length of sim\n",
    "    # This would be faster without a dictionary\n",
    "    s = {'rna_M' : 0., 'monomer_betaGal' : 0., 'protein_betaGal' : 0., \n",
    "         'Lactose_external' : 120440000., 'Lactose_internal' : 0., 'Glucose_external' : 60220000., \n",
    "         'Glucose_internal' : 0., 'protein_Lactose_Permease' : 0., 'dna_Lac_Operon' : 2., 'Biomass' : 1000., \n",
    "         'Lactose_consumed' : 0.} # Starting points\n",
    "  \n",
    "    path = np.insert(torch.tensor(np.fromiter(s.values(), dtype=float)), 0, t, axis=0).reshape(1, 12)\n",
    "\n",
    "    ## Hazard functions\n",
    "    rate_functions = [\n",
    "        lambda s: s['dna_Lac_Operon']*propose_rates[11]*(propose_rates[16] + (s['Lactose_internal']**propose_rates[12]/(propose_rates[13]**propose_rates[12] + s['Lactose_internal']**propose_rates[12]))*(1/(1 + (s['Glucose_external']/propose_rates[14])**propose_rates[15]))),\n",
    "        lambda s: propose_rates[0]*s['rna_M'],\n",
    "        lambda s: propose_rates[1]*s['rna_M'],\n",
    "        lambda s: propose_rates[2]*s['monomer_betaGal']*(s['monomer_betaGal'] - 1)*(s['monomer_betaGal'] - 2)*(s['monomer_betaGal'] - 3),\n",
    "        lambda s: propose_rates[3]*s['protein_betaGal']*s['Lactose_internal']**propose_rates[17]/(propose_rates[4]**propose_rates[17] + s['Lactose_internal']**propose_rates[17]),\n",
    "        lambda s: propose_rates[5]*s['Biomass']*s['Glucose_external']**propose_rates[18]/(propose_rates[6]**propose_rates[18] + s['Glucose_external']**propose_rates[18]),\n",
    "        lambda s: (s['protein_Lactose_Permease']*propose_rates[20]*s['Lactose_external']/(s['Lactose_external'] + propose_rates[21]))*(1 - propose_rates[22]*s['Glucose_external']/(propose_rates[19] + s['Glucose_external'])),\n",
    "        lambda s: propose_rates[7]*s['protein_Lactose_Permease']*s['Lactose_internal']**propose_rates[23]/(propose_rates[8]**propose_rates[23] + s['Lactose_internal']**propose_rates[23]),\n",
    "        lambda s: propose_rates[9]*s['rna_M'],\n",
    "        lambda s: propose_rates[10]*s['protein_betaGal'],\n",
    "        lambda s: propose_rates[10]*s['protein_Lactose_Permease']\n",
    "    ]\n",
    "    \n",
    "    n_func = len(rate_functions)\n",
    "\n",
    "    transition_matrix = torch.tensor([[  1,  0,  0,  0,  0,  0,  0,  0, -1,  0,   0],\n",
    "                                    [  0,  1,  0, -4,  0,  0,  0,  0,  0,  0,   0],\n",
    "                                    [  0,  0,  0,  1,  0,  0,  0,  0,  0, -1,   0],\n",
    "                                    [  0,  0,  0,  0,  0,  0, -1,  1,  0,  0,   0],\n",
    "                                    [  0,  0,  0,  0, -1,  0,  1, -1,  0,  0,   0],\n",
    "                                    [  0,  0,  0,  0,  0, -1,  0,  0,  0,  0,   0],\n",
    "                                    [  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,   0],\n",
    "                                    [  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  -1],\n",
    "                                    [  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,   0],\n",
    "                                    [  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,   0],\n",
    "                                    [  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,   0]])\n",
    "\n",
    "    # Run sim until time limit is reached\n",
    "    # while True:\n",
    "    ## Just loop for x iterations\n",
    "    for i in range(10000):\n",
    "\n",
    "        sampling_weights = [f(s) for f in rate_functions]\n",
    "        total_weight = sum(sampling_weights)\n",
    "\n",
    "        # Sample a rate\n",
    "        probs = np.array([weight / total_weight for weight in sampling_weights])\n",
    "        sample = np.random.choice(n_func, p=probs)\n",
    "        t += np.random.exponential(1.0 / sampling_weights[sample])\n",
    "        \n",
    "        # if t >= stop_time:\n",
    "        #     break\n",
    "\n",
    "        # Update species\n",
    "        new_vals = torch.tensor(np.fromiter(s.values(), dtype=float)) + transition_matrix[1]\n",
    "        \n",
    "        # Update dictionary with new values\n",
    "        s = {list(s.keys())[i] : new_vals[i].item() for i in range(len(new_vals))}\n",
    "\n",
    "        # Add some noise to outputs\n",
    "        # s = torch.normal(s, .25)\n",
    "\n",
    "        path = torch.cat((path, np.insert(new_vals, 0, t, axis=0).reshape(1, 12)), axis=0)\n",
    "\n",
    "    # path = torch.cat((path, np.insert(new_vals, 0, stop_time, axis = 0).reshape(1, 12)), axis=0)\n",
    "    path = torch.flatten(path)\n",
    "\n",
    "    # Mask values onto long tensor so that all samples are of equal length\n",
    "    # mask_len = 100000 - len(path)\n",
    "    # mask = torch.tensor([-1 for _ in range(mask_len)])\n",
    "    # path = torch.cat((path, mask), 0)\n",
    "\n",
    "    return path[12:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "90ad2b76-3f20-4fdd-a934-6e57813e7501",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make sure sim runs\n",
    "test = lac_operon_simulator([0.156666666666667, 0.313333333333333, 1000., 300., 84310., 301., \n",
    "                      9033., 1.18966666666667, 8800000., 0.00783333333333333, \n",
    "                      0.000166666666666667, 0.003, 4., 2900000., 1506., 2., 0.05, \n",
    "                      1., 1., 9033., 35.8, 156576, 0.35, 1.])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1f215b-ffba-4506-bcfb-a36daa7f4ce6",
   "metadata": {},
   "source": [
    "### Define Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "effeec42-84a9-4948-8c72-b6d489cf719f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a prior\n",
    "prior = utils.BoxUniform(\n",
    "    low=torch.tensor([0.1, 0.1, 999., 299., 84309., 300., \n",
    "                      9032, 1., 8799999., 0.005, \n",
    "                      0.0002, 0.002, 3., 2899999., 1500., 1., 0.04, \n",
    "                      .75, .75, 9032., 35., 156575, 0.3, .75]),\n",
    "    high=torch.tensor([0.2, 0.5, 1001., 301., 84311., 302., \n",
    "                      9034., 1.5, 8800001., 0.009, \n",
    "                      0.0001, 0.004, 5., 2900001., 1510., 3., 0.06, \n",
    "                      1.25, 1.25, 9034., 36.5, 156577, 0.4, 1.25])\n",
    ")\n",
    "\n",
    "# Only uniform prior implemented into sbi package currently\n",
    "# Easy to add more manually, for example log normal\n",
    "# prior = utils.LogNormalPrior(\n",
    "#     torch.tensor([np.log(.0015),\n",
    "#                   np.log(.0002),\n",
    "#                   np.log(.003)]), .25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5798f3bc-c68b-4c1c-9ee3-33f2b76372c7",
   "metadata": {},
   "source": [
    "### Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "98806dca-93c4-48c4-a03a-e57bd32fdb96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9735a09db2b64f0dbae0d6eae4a4a205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 200 simulations in 200 batches.:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Neural network successfully converged after 20 epochs."
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "num_sim = 200\n",
    "method = 'SNLE' #SNPE or SNLE or SNRE\n",
    "posterior = infer(\n",
    "    lac_operon_simulator,\n",
    "    prior,\n",
    "    method=method,\n",
    "    num_workers=-1,\n",
    "    num_simulations=num_sim\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d85c348d-6aed-480d-9944-44f1951195e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample some observations with known ground truth\n",
    "obs = torch.tensor([lac_operon_simulator([0.156666666666667, 0.313333333333333, 1000., 300., 84310., 301., \n",
    "                      9033., 1.18966666666667, 8800000., 0.00783333333333333, \n",
    "                      0.000166666666666667, 0.003, 4., 2900000., 1506., 2., 0.05, \n",
    "                      1., 1., 9033., 35.8, 156576, 0.35, 1.]).numpy() for _ in range(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "27b95625-9db9-4c84-9bcb-8cfa53a104c8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5833/2736247501.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# sample the posterior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mposterior\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# SNPE only works with one obs, SNLE will work with more\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sbi/inference/posteriors/mcmc_posterior.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, sample_shape, x, method, thin, warmup_steps, num_chains, init_strategy, init_strategy_num_candidates, mcmc_parameters, mcmc_method, sample_with, num_workers, show_progress_bars)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpotential_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_potential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         initial_params = self._get_initial_params(\n\u001b[0m\u001b[1;32m    237\u001b[0m             \u001b[0minit_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_chains\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_progress_bars\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sbi/inference/posteriors/mcmc_posterior.py\u001b[0m in \u001b[0;36m_get_initial_params\u001b[0;34m(self, init_strategy, num_chains, num_workers, show_progress_bars)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             initial_params = torch.cat(\n\u001b[0;32m--> 363\u001b[0;31m                 \u001b[0;34m[\u001b[0m\u001b[0minit_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_chains\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m             )\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sbi/inference/posteriors/mcmc_posterior.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             initial_params = torch.cat(\n\u001b[0;32m--> 363\u001b[0;31m                 \u001b[0;34m[\u001b[0m\u001b[0minit_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_chains\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m             )\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sbi/inference/posteriors/mcmc_posterior.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mproposal_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproposal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minit_strategy\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sir\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproposal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpotential_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minit_strategy\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"latest_sample\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0mlatest_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIterateParameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mcmc_init_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sbi/samplers/mcmc/init_strategy.py\u001b[0m in \u001b[0;36msir\u001b[0;34m(proposal, potential_fn, transform, sir_num_batches, sir_batch_size, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mbatch_draws\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproposal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msir_batch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0minit_param_candidates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_draws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mlog_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpotential_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_draws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0mlog_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0minit_param_candidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_param_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sbi/inference/potentials/likelihood_based_potential.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, theta, track_gradients)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;31m# Calculate likelihood over trials and in one batch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         log_likelihood_trial_sum = _log_likelihoods_over_trials(\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_o\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mtheta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sbi/inference/potentials/likelihood_based_potential.py\u001b[0m in \u001b[0;36m_log_likelihoods_over_trials\u001b[0;34m(x, theta, net, track_gradients)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;31m# Calculate likelihood in one batch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_gradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0mlog_likelihood_trial_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_repeated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_repeated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;31m# Reshape to (x-trials x parameters), sum over trial-log likelihoods.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         log_likelihood_trial_sum = log_likelihood_trial_batch.reshape(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/nflows/distributions/base.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, inputs, context)\u001b[0m\n\u001b[1;32m     38\u001b[0m                     \u001b[0;34m\"Number of input items must be equal to number of context items.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 )\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/nflows/flows/base.py\u001b[0m in \u001b[0;36m_log_prob\u001b[0;34m(self, inputs, context)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0membedded_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_embedding_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogabsdet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedded_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedded_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlog_prob\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlogabsdet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/nflows/transforms/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, context)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mfuncs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cascade\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuncs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/nflows/transforms/base.py\u001b[0m in \u001b[0;36m_cascade\u001b[0;34m(inputs, funcs, context)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mtotal_logabsdet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfuncs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogabsdet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0mtotal_logabsdet\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlogabsdet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_logabsdet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/nflows/transforms/permutations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, context)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_permute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_permutation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/nflows/transforms/permutations.py\u001b[0m in \u001b[0;36m_permute\u001b[0;34m(inputs, permutation, dim)\u001b[0m\n\u001b[1;32m     35\u001b[0m             )\n\u001b[1;32m     36\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpermutation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mlogabsdet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogabsdet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# sample the posterior\n",
    "samples = posterior.sample((200,), x=obs[0]) # SNPE only works with one obs, SNLE will work with more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc50511e-b1d7-4b70-b9a2-be7524256749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results\n",
    "true_rates = [0.156666666666667, 0.313333333333333, 1000., 300., 84310., 301., \n",
    "              9033., 1.18966666666667, 8800000., 0.00783333333333333, \n",
    "              0.000166666666666667, 0.003, 4., 2900000., 1506., 2., 0.05, \n",
    "              1., 1., 9033., 35.8, 156576, 0.35, 1.]\n",
    "\n",
    "fig, ax = plt.subplots(10,2, figsize = (10,8))\n",
    "\n",
    "group = 0\n",
    "for i in range(10):\n",
    "    ax[i,0].hist(samples[:, group].numpy(), bins = 15)\n",
    "    ax[i,1].hist(samples[:, group+1].numpy(), bins = 15)\n",
    "    \n",
    "    ax[i,0].axvline(true_rates[group], color = \"red\", linewidth=2)\n",
    "    ax[i,1].axvline(true_rates[group+1], color = \"red\", linewidth=2)\n",
    "    \n",
    "    group += 2\n",
    "\n",
    "plt.suptitle(\"Lac Operon SNLE Rate Inference\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
